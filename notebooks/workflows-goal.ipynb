{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-core in /opt/homebrew/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: llama-index-llms-openai in /opt/homebrew/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: llama-index-utils-workflow in /opt/homebrew/lib/python3.11/site-packages (0.3.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/homebrew/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (0.5.8)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (2023.9.0)\n",
      "Requirement already satisfied: httpx in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (0.25.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (3.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (1.25.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (9.5.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (0.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from llama-index-core) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/lib/python3.11/site-packages (from llama-index-core) (1.15.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-llms-openai) (1.55.3)\n",
      "Requirement already satisfied: pyvis<0.4.0,>=0.3.2 in /opt/homebrew/lib/python3.11/site-packages (from llama-index-utils-workflow) (0.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core) (2023.6.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx->llama-index-core) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx->llama-index-core) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.11/site-packages (from httpx->llama-index-core) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core) (2.23.4)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (8.29.0)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/homebrew/lib/python3.11/site-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.1.2)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/homebrew/lib/python3.11/site-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json->llama-index-core) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/homebrew/lib/python3.11/site-packages (from dataclasses-json->llama-index-core) (1.5.1)\n",
      "Requirement already satisfied: decorator in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2>=2.9.6->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.1.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index-core) (24.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/sergii/Library/Python/3.11/lib/python/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U llama-index-core llama-index-llms-openai llama-index-utils-workflow python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import ToolSelection, ToolOutput\n",
    "from llama_index.core.workflow import Event\n",
    "\n",
    "\n",
    "class InputEvent(Event):\n",
    "    input: list[ChatMessage]\n",
    "\n",
    "\n",
    "class ToolCallEvent(Event):\n",
    "    tool_calls: list[ToolSelection]\n",
    "\n",
    "\n",
    "class FunctionOutputEvent(Event):\n",
    "    output: ToolOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "from llama_index.core.llms.function_calling import FunctionCallingLLM\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.tools.types import BaseTool\n",
    "from llama_index.core.workflow import Workflow, StartEvent, StopEvent, step\n",
    "\n",
    "\n",
    "class FuncationCallingAgent(Workflow):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args: Any,\n",
    "        llm: FunctionCallingLLM | None = None,\n",
    "        tools: List[BaseTool] | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tools = tools or []\n",
    "\n",
    "        self.llm = llm or OpenAI()\n",
    "        assert self.llm.metadata.is_function_calling_model\n",
    "\n",
    "        self.memory = ChatMemoryBuffer.from_defaults(llm=llm)\n",
    "        self.sources = []\n",
    "\n",
    "    @step\n",
    "    async def prepare_chat_history(self, ev: StartEvent) -> InputEvent:\n",
    "        # clear sources\n",
    "        self.sources = []\n",
    "\n",
    "        # get user input\n",
    "        user_input = ev.input\n",
    "        user_msg = ChatMessage(role=\"user\", content=user_input)\n",
    "        self.memory.put(user_msg)\n",
    "\n",
    "        # get chat history\n",
    "        chat_history = self.memory.get()\n",
    "        return InputEvent(input=chat_history)\n",
    "\n",
    "    @step\n",
    "    async def handle_llm_input(\n",
    "        self, ev: InputEvent\n",
    "    ) -> ToolCallEvent | StopEvent:\n",
    "        chat_history = ev.input\n",
    "\n",
    "        response = await self.llm.achat_with_tools(\n",
    "            self.tools, chat_history=chat_history\n",
    "        )\n",
    "        self.memory.put(response.message)\n",
    "\n",
    "        tool_calls = self.llm.get_tool_calls_from_response(\n",
    "            response, error_on_no_tool_call=False\n",
    "        )\n",
    "\n",
    "        if not tool_calls:\n",
    "            return StopEvent(\n",
    "                result={\"response\": response, \"sources\": [*self.sources]}\n",
    "            )\n",
    "        else:\n",
    "            return ToolCallEvent(tool_calls=tool_calls)\n",
    "\n",
    "    @step\n",
    "    async def handle_tool_calls(self, ev: ToolCallEvent) -> InputEvent:\n",
    "        tool_calls = ev.tool_calls\n",
    "        tools_by_name = {tool.metadata.get_name(): tool for tool in self.tools}\n",
    "\n",
    "        tool_msgs = []\n",
    "\n",
    "        # call tools -- safely!\n",
    "        for tool_call in tool_calls:\n",
    "            tool = tools_by_name.get(tool_call.tool_name)\n",
    "            additional_kwargs = {\n",
    "                \"tool_call_id\": tool_call.tool_id,\n",
    "                \"name\": tool.metadata.get_name(),\n",
    "            }\n",
    "            if not tool:\n",
    "                tool_msgs.append(\n",
    "                    ChatMessage(\n",
    "                        role=\"tool\",\n",
    "                        content=f\"Tool {tool_call.tool_name} does not exist\",\n",
    "                        additional_kwargs=additional_kwargs,\n",
    "                    )\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                tool_output = tool(**tool_call.tool_kwargs)\n",
    "                self.sources.append(tool_output)\n",
    "                tool_msgs.append(\n",
    "                    ChatMessage(\n",
    "                        role=\"tool\",\n",
    "                        content=tool_output.content,\n",
    "                        additional_kwargs=additional_kwargs,\n",
    "                    )\n",
    "                )\n",
    "            except Exception as e:\n",
    "                tool_msgs.append(\n",
    "                    ChatMessage(\n",
    "                        role=\"tool\",\n",
    "                        content=f\"Encountered error in tool call: {e}\",\n",
    "                        additional_kwargs=additional_kwargs,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        for msg in tool_msgs:\n",
    "            self.memory.put(msg)\n",
    "\n",
    "        chat_history = self.memory.get()\n",
    "        return InputEvent(input=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Useful function to add two numbers.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def multiply(x: int, y: int) -> int:\n",
    "    \"\"\"Useful function to multiply two numbers.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "def update_goal_vision(vision: str) -> str:\n",
    "    \"\"\"Update the goal.\n",
    "    - `vision` (str): The new vision for the goal.\n",
    "    \"\"\"\n",
    "    print(f\"Updating goal with vision {vision}\")\n",
    "    return f\"Goal updated.\"\n",
    "\n",
    "\n",
    "def update_goal_milestone(milestone_id: str, description: str) -> str:\n",
    "    \"\"\"Update the milestone.\n",
    "    - `milestone_id` (str): The ID of the milestone to update.\n",
    "    - `description` (str): The new description for the milestone.\n",
    "    \"\"\"\n",
    "    print(f\"Updating milestone {milestone_id}, {description}\")\n",
    "    return f\"Milestone updated.\"\n",
    "\n",
    "\n",
    "def delete_goal_milestone(\n",
    "    milestone_id: str,\n",
    ") -> str:\n",
    "    \"\"\"Delete the milestone.\n",
    "    - `milestone_id` (str): The ID of the milestone to delete.\n",
    "    \"\"\"\n",
    "    print(f\"Deleting milestone {milestone_id}\")\n",
    "    return f\"Milestone deleted.\"\n",
    "\n",
    "tools = [\n",
    "    FunctionTool.from_defaults(add),\n",
    "    FunctionTool.from_defaults(multiply),\n",
    "    FunctionTool.from_defaults(update_goal_vision),\n",
    "    FunctionTool.from_defaults(update_goal_milestone),\n",
    "    FunctionTool.from_defaults(delete_goal_milestone),\n",
    "]\n",
    "\n",
    "agent = FuncationCallingAgent(\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"), tools=tools, timeout=120, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat_history\n",
      "Step prepare_chat_history produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event StopEvent\n"
     ]
    }
   ],
   "source": [
    "ret = await agent.run(input=\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(ret[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat_history\n",
      "Step prepare_chat_history produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event ToolCallEvent\n",
      "Running step handle_tool_calls\n",
      "Step handle_tool_calls produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event ToolCallEvent\n",
      "Running step handle_tool_calls\n",
      "Step handle_tool_calls produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event StopEvent\n"
     ]
    }
   ],
   "source": [
    "ret = await agent.run(input=\"What is (2123 + 2321) * 312?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: The result of (2123 + 2321) * 312 is 1,386,528.\n"
     ]
    }
   ],
   "source": [
    "print(ret[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat_history\n",
      "Step prepare_chat_history produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event ToolCallEvent\n",
      "Running step handle_tool_calls\n",
      "Updating milestone 4, Become a Senior Developer\n",
      "Step handle_tool_calls produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event StopEvent\n"
     ]
    }
   ],
   "source": [
    "ret = await agent.run(input=\"\"\"My goal:\n",
    "Milestone 1: Find a new job\n",
    "Milestone 2: Get a promotion\n",
    "Milestone 3: Learn a new skill\n",
    "Milestone 4: Get a promotion\n",
    "Milestone 5: Ask for a raise\n",
    "Milestone 6: Start investing\n",
    "Milestone 7: Buy a house\n",
    "Milestone 8: Start a business.\n",
    "                      \n",
    "Change my milestone #4, I want to be a Senior Developer\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Milestone #4 has been updated to \"Become a Senior Developer.\" If you need any further changes or assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(ret[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step prepare_chat_history\n",
      "Step prepare_chat_history produced event InputEvent\n",
      "Running step handle_llm_input\n",
      "Step handle_llm_input produced event StopEvent\n",
      "assistant: Your final goal includes the following milestones:\n",
      "\n",
      "1. Find a new job\n",
      "2. Get a promotion\n",
      "3. Learn a new skill\n",
      "4. Become a Senior Developer\n",
      "5. Ask for a raise\n",
      "6. Start investing\n",
      "7. Buy a house\n",
      "8. Start a business\n",
      "\n",
      "If you need to make any changes or add more details, just let me know!\n"
     ]
    }
   ],
   "source": [
    "ret = await agent.run(input=\"What is the final goal?\")\n",
    "print(ret[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
